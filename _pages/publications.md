---
layout: page
permalink: /publications/
title: publications
description: publications by categories in reversed chronological order.
years: [2022]
nav: true
nav_order: 1
---
<!-- _pages/publications.md -->
<div class="publications">
<hr>
<h3><b>Smartphone-Based Tactile Feedback System Providing Navigation and Obstacle Avoidance to the Blind and Visually Impaired</b></h3>

<strong>Published at 2022 5th International Conference on Advances in Science and Technology (ICAST) <a href="https://sites.google.com/somaiya.edu/ieee-icast-2022/home?authuser=0">IEEE-ICAST-2022</a>.</strong>
<br>
<strong>Abstract:</strong> People with vision impairments and other visual disorders require support to complete daily tasks like moving around and discovering new places. They may find it difficult to navigate through a new place and could be put in danger if they run into unforeseen barriers or could get lost easily. This paper discusses a solution to aid the blind and visually impaired navigate independently while avoiding obstacles in their path. The system has two operational modes, Outdoor Navigation and Indoor Navigation, and it alerts the user through vibration (tactile) and audio feedback. While the Indoor mode accompanies a user to a labelled site, the Outdoor mode leads them to a geographical destination. The solution was able to reduce the Clearance time by 27.35 percent and the Obstacle hit rate by 66.6 percent. The system is hassle-free, comfortable to use and affordable because it requires only the user's smartphone and a custom-made hardware waist belt.

<strong>Publication:</strong><a href="https://ieeexplore.ieee.org/abstract/document/10039535">https://ieeexplore.ieee.org/abstract/document/10039535</a>
<br>

<strong>Project:</strong> <a href="/projects/1_project/">Eye of God</a>
<hr>

<!-- {%- for y in page.years %}
  <h2 class="year">{{y}}</h2>
  {% bibliography -f papers -q @*[year={{y}}]* %}
{% endfor %} -->

<h3><b>Feature-Rich Long-term Bitcoin Trading Assistant</b></h3>
<strong>Published at 2nd International Conference on Intelligent Vision and Computing <a href="https://www.icivc22.scrs.in">ICIVC 2022</a>.</strong>
<br>
<strong>Abstract:</strong> For a long time predicting, studying and analyzing financial indices has been of major interest for the financial community. Recently, there has been a growing interest in the Deep-Learning community to make use of reinforcement learning which has surpassed many of the previous benchmarks in a lot of fields. Our method provides a feature rich environment for the reinforcement learning agent to work on. The aim is to provide long term profits to the user so, we took into consideration the most reliable technical indicators. We have also developed a custom indicator which would provide better insights of the Bitcoin market to the user. The Bitcoin market follows the emotions and sentiments of the traders, so another element of our trading environment is the overall daily Sentiment Score of the market on Twitter. The agent is tested for a period of 685 days which also included the volatile period of Covid-19. It has been capable of providing reliable recommendations which give an average profit of about 69%. Finally, the agent is also capable of suggesting the optimal actions to the user through a website. Users on the website can also access the visualizations of the indicators to help fortify their decisions.
<br>
<strong>Publication:</strong> <a href="https://link.springer.com/chapter/10.1007/978-3-031-31164-2_36">https://link.springer.com/chapter/10.1007/978-3-031-31164-2_36</a> <br>
<strong>Project:</strong> <a href="/projects/4_project/">Investing Assistant</a>
</div>


<hr>
<h3><b>
ZeroSearch: Local Image Search from Text with Zero Shot Learning</b></h3>
<!-- <strong>Accepted at 2nd International Conference on Intelligent Vision and Computing <a href="https://www.icivc22.scrs.in">ICIVC 2022</a>.</strong> -->
<!-- <br> -->
<strong>Abstract:</strong> — The problem of organizing and finding images in a user's directory has become increasingly challenging due to the rapid growth in the number of images captured on personal devices. This paper presents a solution that utilizes zero shot learning to create image queries with only user provided text descriptions. The paper's primary contribution is the development of an algorithm that utilizes pre-trained models to extract features from images. The algorithm uses OWL to check for the presence of bounding boxes and sorts images based on
cosine similarity scores. The algorithm's output is a list of images sorted in descending order of similarity, helping users to locate specific images more efficiently. The paper's experiments were conducted using a custom dataset to simulate a user’s image directory and evaluated the accuracy, inference time, and size of the models. The results showed that the VGG model achieved the highest accuracy, while the Resnet50 and
InceptionV3 models had the lowest inference time and size. The paper's proposed algorithm provides an effective and efficient solution for organizing and finding images in a user's local directory. The algorithm's performance and flexibility make it suitable for various applications, including personal image organization and search engines. Code and dataset for zerosearch are available at: https://github.com/NainaniJatinZ/zerosearch

<!-- <br> -->
<strong>Preprint available:</strong> <a href="https://arxiv.org/abs/2305.00715">https://arxiv.org/abs/2305.00715</a> <br>

